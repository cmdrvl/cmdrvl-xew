from __future__ import annotations

import argparse
import hashlib
import os
import re
import tempfile
import time
import urllib.request
from pathlib import Path
from urllib.parse import urljoin
from urllib.parse import urlparse
import zipfile

from . import __version__
from .exit_codes import ExitCode, exit_invocation_error, exit_processing_error
from .util import sha256_file


def _default_arelle_xdg_config_home() -> Path:
    configured = os.environ.get("XEW_ARELLE_XDG_CONFIG_HOME")
    if configured:
        return Path(configured)
    return Path(tempfile.gettempdir()) / "cmdrvl-xew-arelle"


def _download_filename_from_url(url: str) -> str:
    parsed = urlparse(url)
    if parsed.scheme not in ("http", "https"):
        exit_invocation_error(f"URL must use http/https: {url}")
    name = Path(parsed.path).name
    if not name:
        exit_invocation_error(f"URL must end with a filename: {url}")
    return name


def _looks_like_directory_url(url: str) -> bool:
    parsed = urlparse(url)
    if not parsed.scheme or not parsed.netloc:
        return False
    if parsed.path.endswith("/"):
        return True
    # Treat URLs without an extension as directory URLs (e.g. .../dei/2025).
    return Path(parsed.path).suffix == ""


def _normalize_base_url(url: str) -> str:
    parsed = urlparse(url)
    if parsed.scheme not in ("http", "https"):
        exit_invocation_error(f"URL must use http/https: {url}")
    if not parsed.netloc:
        exit_invocation_error(f"URL must include a host: {url}")
    base = url
    if not base.endswith("/"):
        base += "/"
    return base


_HREF_RE = re.compile(r'href="([^"]+)"', re.IGNORECASE)


def _fetch_text(
    url: str,
    *,
    user_agent: str,
    min_interval_seconds: float,
    last_request_time: list[float],
) -> str:
    # Basic rate limiting across requests.
    now = time.monotonic()
    elapsed = now - last_request_time[0]
    if elapsed < min_interval_seconds:
        time.sleep(min_interval_seconds - elapsed)

    req = urllib.request.Request(url, headers={"User-Agent": user_agent})
    with urllib.request.urlopen(req) as resp:
        data = resp.read()
    last_request_time[0] = time.monotonic()
    return data.decode("utf-8", errors="replace")


def _is_arelle_taxonomy_package_zip(path: Path) -> bool:
    if path.suffix.lower() != ".zip":
        return False
    try:
        with zipfile.ZipFile(path) as zf:
            return any(name.endswith("META-INF/taxonomyPackage.xml") for name in zf.namelist())
    except zipfile.BadZipFile:
        return False


def _catalog_xml(base_url: str, rewrite_prefix: str) -> str:
    base_url = _normalize_base_url(base_url)
    mappings = [base_url]
    if base_url.startswith("https://"):
        mappings.append("http://" + base_url[len("https://"):])
    elif base_url.startswith("http://"):
        mappings.append("https://" + base_url[len("http://"):])

    lines = ['<catalog xmlns="urn:oasis:names:tc:entity:xmlns:xml:catalog">']
    for mapping in sorted(set(mappings)):
        lines.append(f'  <rewriteURI uriStartString="{mapping}" rewritePrefix="{rewrite_prefix}"/>')
    lines.append("</catalog>")
    return "\n".join(lines) + "\n"


def _taxonomy_package_xml(base_url: str) -> str:
    base_url = _normalize_base_url(base_url)
    identifier = base_url.rstrip("/")
    version = base_url.rstrip("/").split("/")[-1]
    name = f"Mirror {identifier}"
    description = "Local mirror for offline Arelle resolution (generated by cmdrvl-xew)."
    # Keep this minimal; Arelle can parse without schema validation when offline.
    return (
        "<tp:taxonomyPackage xml:lang='en' xmlns:tp='http://xbrl.org/2016/taxonomy-package'>\n"
        f"<tp:identifier>{identifier}</tp:identifier>\n"
        f"<tp:name>{name}</tp:name>\n"
        f"<tp:description>{description}</tp:description>\n"
        f"<tp:version>{version}</tp:version>\n"
        "</tp:taxonomyPackage>\n"
    )


def _mirror_directory(
    base_url: str,
    *,
    download_root: Path,
    user_agent: str,
    min_interval_seconds: float,
    last_request_time: list[float],
    force: bool,
) -> tuple[Path, list[dict]]:
    base_url = _normalize_base_url(base_url)
    parsed = urlparse(base_url)
    rel_path = parsed.path.lstrip("/").rstrip("/")
    mirror_dir = (download_root / "_mirror" / parsed.netloc / rel_path).resolve()
    mirror_dir.mkdir(parents=True, exist_ok=True)

    index_html = _fetch_text(
        base_url,
        user_agent=user_agent,
        min_interval_seconds=min_interval_seconds,
        last_request_time=last_request_time,
    )
    hrefs = _HREF_RE.findall(index_html)
    xsd_files = sorted(
        {
            href
            for href in hrefs
            if href
            and not href.startswith("?")
            and not href.startswith("/")
            and not href.endswith("/")
            and href.lower().endswith(".xsd")
        }
    )
    if not xsd_files:
        exit_processing_error(f"No .xsd files found at directory URL: {base_url}")

    downloaded: list[dict] = []
    for filename in xsd_files:
        file_url = urljoin(base_url, filename)
        dest = mirror_dir / filename
        path, digest, size = _download_url_to_file(
            file_url,
            dest,
            user_agent=user_agent,
            min_interval_seconds=min_interval_seconds,
            last_request_time=last_request_time,
            force=force,
        )
        downloaded.append({"url": file_url, "path": str(path), "sha256": digest, "size": size})

    meta_inf = mirror_dir / "META-INF"
    meta_inf.mkdir(parents=True, exist_ok=True)

    taxonomy_pkg_path = meta_inf / "taxonomyPackage.xml"
    if not taxonomy_pkg_path.exists():
        taxonomy_pkg_path.write_text(_taxonomy_package_xml(base_url), encoding="utf-8")

    catalog_path = meta_inf / "catalog.xml"
    if not catalog_path.exists():
        # Mirror files live at the package root; from META-INF/, that is "../".
        catalog_path.write_text(_catalog_xml(base_url, "../"), encoding="utf-8")

    return taxonomy_pkg_path, downloaded


def _download_url_to_file(
    url: str,
    dest: Path,
    *,
    user_agent: str,
    min_interval_seconds: float,
    last_request_time: list[float],
    force: bool,
) -> tuple[Path, str, int]:
    """Download URL bytes to dest and return (path, sha256, size)."""
    if dest.exists() and not force:
        digest, size = sha256_file(dest)
        return dest, digest, size

    # Basic rate limiting across downloads.
    now = time.monotonic()
    elapsed = now - last_request_time[0]
    if elapsed < min_interval_seconds:
        time.sleep(min_interval_seconds - elapsed)

    req = urllib.request.Request(url, headers={"User-Agent": user_agent})
    tmp = dest.with_name(dest.name + ".tmp")
    tmp.parent.mkdir(parents=True, exist_ok=True)

    h = hashlib.sha256()
    size = 0
    with urllib.request.urlopen(req) as resp:
        with tmp.open("wb") as f:
            while True:
                chunk = resp.read(1024 * 1024)
                if not chunk:
                    break
                f.write(chunk)
                h.update(chunk)
                size += len(chunk)

    # Atomic-ish move into place.
    tmp.replace(dest)
    last_request_time[0] = time.monotonic()
    return dest, h.hexdigest(), size


def run_arelle_install_packages(args: argparse.Namespace) -> int:
    """Install/register taxonomy packages in an Arelle config home.

    This writes/updates Arelle's taxonomy package registry file:
      <XDG_CONFIG_HOME>/arelle/taxonomyPackages.json

    Callers should pass the same `--arelle-xdg-config-home` to `cmdrvl-xew pack`
    and use `--resolution-mode offline_only` for production determinism.
    """
    packages = list(getattr(args, "package", None) or [])
    urls = list(getattr(args, "url", None) or [])
    if not packages and not urls:
        exit_invocation_error("At least one --package or --url is required")

    xdg_home = Path(getattr(args, "arelle_xdg_config_home", None) or _default_arelle_xdg_config_home())
    xdg_home.mkdir(parents=True, exist_ok=True)

    package_paths: list[Path] = []
    for raw in packages:
        p = Path(raw).expanduser().resolve()
        if not p.exists():
            exit_invocation_error(f"Taxonomy package not found: {p}")
        package_paths.append(p)

    download_dir = Path(
        getattr(args, "download_dir", None) or (xdg_home / "arelle" / "taxonomy-packages")
    ).expanduser().resolve()
    force = bool(getattr(args, "force", False))
    min_interval = float(getattr(args, "min_interval", 0.2))
    if min_interval < 0:
        exit_invocation_error("--min-interval must be >= 0")

    downloaded: list[dict] = []
    mirrored: list[dict] = []
    user_agent = ""
    if urls:
        download_dir.mkdir(parents=True, exist_ok=True)
        from .sec_policy import SECRequestConfig

        user_agent = (getattr(args, "user_agent", None) or "").strip()
        if not user_agent:
            user_agent = SECRequestConfig(application_version=__version__).get_user_agent()

        # Align with EDGAR fetch rules: require contact info to avoid default/bot UAs.
        try:
            from .edgar_fetch import _validate_user_agent  # type: ignore

            _validate_user_agent(user_agent)
        except Exception as e:
            exit_invocation_error(str(e))

        last_request_time = [0.0]
        mirror_base_urls: set[str] = set()
        for url in urls:
            if _looks_like_directory_url(url):
                mirror_base_urls.add(_normalize_base_url(url))
                continue
            filename = _download_filename_from_url(url)
            dest = download_dir / filename
            path, digest, size = _download_url_to_file(
                url,
                dest,
                user_agent=user_agent,
                min_interval_seconds=min_interval,
                last_request_time=last_request_time,
                force=force,
            )
            downloaded.append({"url": url, "path": str(path), "sha256": digest, "size": size})

            if path.suffix.lower() == ".zip":
                if _is_arelle_taxonomy_package_zip(path):
                    package_paths.append(path.resolve())
                else:
                    # SEC "zip" downloads are often plain archives (not Arelle taxonomy packages).
                    # Fall back to mirroring the parent directory (download .xsd files + catalog.xml).
                    mirror_base_urls.add(_normalize_base_url(url.rsplit("/", 1)[0]))

        for base_url in sorted(mirror_base_urls):
            catalog_path, mirror_downloads = _mirror_directory(
                base_url,
                download_root=download_dir,
                user_agent=user_agent,
                min_interval_seconds=min_interval,
                last_request_time=last_request_time,
                force=force,
            )
            package_root = str(Path(catalog_path).parent.parent)
            mirrored.append({"base_url": base_url, "package_dir": package_root, "files": mirror_downloads})
            package_paths.append(Path(catalog_path).resolve())

    previous_xdg = os.environ.get("XDG_CONFIG_HOME")
    os.environ["XDG_CONFIG_HOME"] = str(xdg_home)
    try:
        from arelle import Cntlr, PackageManager  # type: ignore

        from .sec_policy import SECRequestConfig

        cntlr = Cntlr.Cntlr(logFileName="logToBuffer")
        cntlr.webCache.httpUserAgent = user_agent or SECRequestConfig(application_version=__version__).get_user_agent()

        # In command-line mode, Arelle doesn't load taxonomyPackages.json by default.
        # Force loading so addPackage/save reads/writes the expected registry file.
        PackageManager.init(cntlr, loadPackagesConfig=True)

        # Arelle versions differ in how taxonomyPackages.json is keyed. Newer versions key by
        # package "identifier" and may raise KeyError when older configs are missing it.
        cfg = getattr(PackageManager, "packagesConfig", None)
        if isinstance(cfg, dict):
            pkgs = cfg.get("packages")
            if isinstance(pkgs, list):
                changed = False
                for pkg in pkgs:
                    if isinstance(pkg, dict) and "identifier" not in pkg:
                        pkg["identifier"] = pkg.get("URL") or f"{pkg.get('name', '')}|{pkg.get('version', '')}"
                        changed = True
                if changed and hasattr(PackageManager, "packagesConfigChanged"):
                    PackageManager.packagesConfigChanged = True

        if downloaded:
            print(f"Downloaded {len(downloaded)} URL file(s) to {download_dir}:")
            for entry in downloaded:
                print(
                    f"  {Path(entry['path']).name} sha256={entry['sha256']} bytes={entry['size']} url={entry['url']}"
                )
        if mirrored:
            print(f"Mirrored {len(mirrored)} taxonomy directory URL(s) into local catalogs:")
            for entry in mirrored:
                print(f"  {entry['base_url']} -> {entry['package_dir']} ({len(entry['files'])} file(s))")

        installed: list[dict] = []
        for p in package_paths:
            info = PackageManager.addPackage(cntlr, str(p))
            if not info:
                exit_processing_error(f"Arelle could not load taxonomy package: {p}")
            installed.append(info)

        PackageManager.rebuildRemappings(cntlr)
        PackageManager.save(cntlr)

        registry_path = Path(cntlr.userAppDir) / "taxonomyPackages.json"
        print(f"Arelle XDG_CONFIG_HOME: {xdg_home}")
        print(f"Taxonomy package registry: {registry_path}")
        print(f"Installed {len(installed)} package(s):")
        for info in installed:
            name = info.get("name") or "unknown"
            version = info.get("version") or "unknown"
            identifier = info.get("identifier") or ""
            suffix = f" id={identifier}" if identifier else ""
            print(f"  {name} version={version}{suffix}")

        return ExitCode.SUCCESS

    except SystemExit:
        raise
    except Exception as e:
        exit_processing_error(f"Failed to install taxonomy packages via Arelle: {e}")
    finally:
        if previous_xdg is None:
            os.environ.pop("XDG_CONFIG_HOME", None)
        else:
            os.environ["XDG_CONFIG_HOME"] = previous_xdg
